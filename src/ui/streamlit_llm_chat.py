import os
import sys
import streamlit as st

# Aseguramos que el proyecto ra铆z est茅 en sys.path
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
if PROJECT_ROOT not in sys.path:
    sys.path.append(PROJECT_ROOT)

from src.nlp.llm_ev_assistant import run_llm_assistant


def main():
    st.set_page_config(page_title="Asistente EV con LLM", page_icon="")
    st.title(" Asistente de Carga de Veh铆culos El茅ctricos (LLM + Modelo HF)")
    st.write(
        "Este asistente usa un LLM (Groq + Qwen) para entender tu mensaje, "
        "completa la informaci贸n de la sesi贸n de carga y llama a tu modelo "
        "de predicci贸n en Hugging Face para estimar la energ铆a cargada."
    )

    if "history" not in st.session_state:
        st.session_state.history = []

    # Mostrar historial
    for role, msg in st.session_state.history:
        if role == "user":
            st.chat_message("user").markdown(msg)
        else:
            st.chat_message("assistant").markdown(msg)

    # Input del usuario (estilo chat)
    user_msg = st.chat_input("Describe tu sesi贸n de carga...")
    if user_msg:
        # A帽adimos al historial
        st.session_state.history.append(("user", user_msg))
        st.chat_message("user").markdown(user_msg)

        with st.spinner("Pensando..."):
            try:
                answer = run_llm_assistant(user_msg)
            except Exception as exc:
                answer = (
                    "Ocurri贸 un error al procesar tu mensaje:\n\n"
                    f"`{exc}`\n\n"
                    "Verifica que las variables de entorno HF_TOKEN y GROQ_API_KEY "
                    "est茅n configuradas y que EV-DB.csv existe en la carpeta data/."
                )

        st.session_state.history.append(("assistant", answer))
        st.chat_message("assistant").markdown(answer)


if __name__ == "__main__":
    main()
