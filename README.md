# ğŸš—ğŸ”‹ EV Charging Assistant â€” LLM + ANN Prediction

This project provides an intelligent assistant capable of analyzing EV charging sessions using **LLMs (Groq + Qwen3)** and a **neural network model** trained on EV charging patterns.  
It extracts structured information from natural language, identifies the vehicle from the EV-DB dataset, computes physical properties of the charge, and predicts the **energy consumed (kWh)** using a model hosted on Hugging Face.

The full application runs locally and exposes a **Streamlit chatbot UI** where users can interact naturally.

---

# ğŸš€ Getting Started

## âœ” Requirements

- **Python 3.11**
- macOS users **must** install a version of Python that supports TensorFlow  
  (ANN was originally trained with TF)
- HuggingFace token + Groq API key
- Recommended: virtual environment

---

# âš™ 1. Create and Activate Virtual Environment

```bash
python3 -m venv venv
source venv/bin/activate
```

If using Windows PowerShell:

```powershell
venv\Scripts\activate
```

---

# ğŸ“¦ 2. Install Dependencies

Upgrade pip:

```bash
python -m pip install --upgrade pip
```

Install project dependencies:

```bash
pip install -r requirements.txt
```

---

# ğŸ Practical Hack for macOS (TensorFlow + Keras Compatibility)

TensorFlow versions on macOS (especially ARM/M1/M2 chips) often conflict with modern Keras.  
Use this **minimal hack** so your ANN model loads successfully.

### ğŸ”§ Step 1 â€” Remove any preinstalled Keras

```bash
pip uninstall -y keras
```

### ğŸ”§ Step 2 â€” Install Keras 3 manually (no dependency resolution)

```bash
pip install keras==3.3.3 --no-deps
```

### ğŸ”§ Step 3 â€” Install missing TensorFlow dependency (`optree`)

```bash
pip install optree
```

These steps allow your HuggingFace snapshot's ANN model to load without errors.

---

# ğŸ”‘ 3. Environment Variables

Create a simple `env.sh` file:

```bash
export HF_TOKEN="your-hf-token-here"
export GROQ_API_KEY="your-groq-key-here"
```

Load it before running the app:

```bash
source env.sh
```

---

# ğŸ–¥ 4. Run the Application (Streamlit UI)

```bash
streamlit run src/ui/streamlit_llm_chat.py
```

This launches the EV Assistant at:

â¡ **http://localhost:8501**

---

# ğŸ’¬ Example Questions

Try natural language queries such as:

> â€œTengo un Abarth 500e Hatchback de 2023, lo carguÃ© de 20% a 60% y tardÃ³ 1.5 horas.â€

The system will:

1. Extract vehicle + session info  
2. Match the car inside the EV-DB dataset  
3. Compute SoC difference, charging rate, energy estimate  
4. Ask follow-up questions if needed  
5. Run the ANN model to predict **energy consumed**  
6. Generate an LLM explanation in Spanish  

---

# ğŸ“ Project Structure (Simplified)

```
project/
 â”œâ”€â”€ src/
 â”‚   â”œâ”€â”€ model/               # ANN model loading + HuggingFace snapshot
 â”‚   â”œâ”€â”€ pipeline/            # LLM extraction + EV-DB matching
 â”‚   â””â”€â”€ ui/
 â”‚       â”œâ”€â”€ streamlit_llm_chat.py   # Chatbot UI
 â”‚       â””â”€â”€ ...
 â”œâ”€â”€ data/
 â”‚   â””â”€â”€ EV-DB.csv            # Vehicle specifications database
 â”œâ”€â”€ requirements.txt
 â”œâ”€â”€ env.sh
 â””â”€â”€ README.md
```

---

# ğŸ›  Troubleshooting

### âŒ The vehicle is not found in EV-DB  
Use a fuzzy-matching implementation in `find_vehicle_row()`.

### âŒ Import errors involving TF/Keras  
Use the macOS fix above â€” Keras/TensorFlow compatibility is strict on Apple Silicon.

### âŒ LLM does not respond  
Ensure your environment variables are loaded correctly:

```bash
echo $HF_TOKEN
echo $GROQ_API_KEY
```

---

# ğŸ‰ You're Ready to Go!
